{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_images_folder = 'C:/CompetitionData/train_images'\n",
    "train_masks_folder = 'C:/CompetitionData/train_masks'\n",
    "new_train_images_folder = 'C:/newData/new_train_images'\n",
    "new_train_masks_folder = 'C:/newData/new_train_masks'\n",
    "train_path = 'C:/CompetitionData/stage1_train/'\n",
    "train_ids = next(os.walk(train_path))[1]\n",
    "#image shape to resize to\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256\n",
    "IMG_CHANNELS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rgbToGray(img):\n",
    "    grayImg = 0.0722*img[:,:,0] + 0.7152*img[:,:,1] + 0.2126*img[:,:,2]\n",
    "    return np.expand_dims(grayImg, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resizer(img):\n",
    "    desired_size = resize(img, (IMG_HEIGHT, IMG_WIDTH,1), mode='constant', preserve_range=True)\n",
    "    return desired_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing train images and masks ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                          | 0/670 [00:00<?, ?it/s]\n",
      "  0%|▎                                                                                 | 3/670 [00:00<01:17,  8.60it/s]\n",
      "  1%|▍                                                                                 | 4/670 [00:00<02:00,  5.53it/s]\n",
      "  1%|▉                                                                                 | 8/670 [00:00<01:18,  8.47it/s]\n",
      "  1%|█▏                                                                               | 10/670 [00:01<01:10,  9.33it/s]\n",
      "  2%|█▎                                                                               | 11/670 [00:01<01:10,  9.35it/s]\n",
      "  2%|█▍                                                                               | 12/670 [00:01<01:34,  6.96it/s]\n",
      "  2%|█▊                                                                               | 15/670 [00:01<01:23,  7.86it/s]\n",
      "  3%|██▏                                                                              | 18/670 [00:02<01:15,  8.63it/s]\n",
      "Exception in thread Thread-31:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda\\envs\\py35\\lib\\threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Anaconda\\envs\\py35\\lib\\site-packages\\tqdm\\_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"C:\\Anaconda\\envs\\py35\\lib\\_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 670/670 [02:15<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.bool)\n",
    "\n",
    "print('Getting and resizing train images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    fn_ = ''.join([train_path,id_,'/images/',id_,'.png'])\n",
    "    \n",
    "    img = imread(fn_)[:,:,:3]\n",
    "    orig_file_height, orig_file_width = img.shape[0:2]\n",
    "    \n",
    "    #grey scale conversion\n",
    "    img = rgbToGray(img)\n",
    "    \n",
    "    #pad if necessary\n",
    "    #if (img.shape[0] <= IMG_HEIGHT) and (img.shape[1] <= IMG_WIDTH):\n",
    "    #    img = paddingImg(img)\n",
    "            \n",
    "    #resize if necessary\n",
    "    #else:\n",
    "    if (orig_file_height != IMG_HEIGHT) or (orig_file_width != IMG_WIDTH):\n",
    "        img = resizer(img)\n",
    " \n",
    "    #Convert to float before exposure shift\n",
    "    #img = np.array(img, dtype=np.float)\n",
    "    \n",
    "    #imgadapt = img_as_float(img)\n",
    "    \n",
    "    \n",
    "    #change exposure to adaptive histogram\n",
    "    #imgadapt = exposure.equalize_adapthist(img, clip_limit=0.03)\n",
    "    \n",
    "    #convert it back to uint\n",
    "    #img = np.array(imgadapt, dtype=np.uint8)\n",
    "    \n",
    "\n",
    "    X_train[n] = img\n",
    "    \n",
    "    #consolidate masks\n",
    "\n",
    "        \n",
    "    mask_X = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "    for mask_file in next(os.walk(''.join([train_path,id_,'/masks/'])))[2]:\n",
    "        mask_ = imread(''.join([train_path,id_,'/masks/',mask_file]))\n",
    "        \n",
    "        #if (orig_file_height <= IMG_HEIGHT) and (orig_file_width <= IMG_WIDTH):\n",
    "            #print('padding')\n",
    "         #   mask_ = paddingMask(mask_)\n",
    "        #else:\n",
    "            #print('sizer')\n",
    "        if (orig_file_height != IMG_HEIGHT) or (orig_file_width != IMG_WIDTH):\n",
    "            \n",
    "            mask_ = maskResizer(mask_)\n",
    "        else:\n",
    "            mask_ = np.expand_dims(mask_, axis=2)\n",
    "            #print(mask_.shape)     \n",
    "        mask_X = np.maximum(mask_X, mask_)\n",
    "    \n",
    "    Y_train[n] = mask_X\n",
    "\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we create two instances with the same arguments\n",
    "data_gen_args = dict(featurewise_center=True,\n",
    "                     featurewise_std_normalization=True,\n",
    "                     rotation_range=90.,\n",
    "                     horizontal_flip=True,\n",
    "                     vertical_flip=True,\n",
    "                     width_shift_range=0.2,\n",
    "                     height_shift_range=0.2,\n",
    "                     zoom_range=0.2)\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "# Provide the same seed and keyword arguments to the fit and flow methods\n",
    "seed = 1\n",
    "image_datagen.fit(X_train, augment=True)\n",
    "mask_datagen.fit(Y_train, augment=True)\n",
    "\n",
    "i = 0    \n",
    "for batch in image_datagen.flow(\n",
    "    X_train,\n",
    "    seed=seed,\n",
    "    save_to_dir=new_train_images_folder,\n",
    "    batch_size=32):\n",
    "         i += 1\n",
    "         if i > 200:\n",
    "            break\n",
    "        \n",
    "n = 0\n",
    "\n",
    "for batch in mask_datagen.flow(\n",
    "    Y_train,\n",
    "    seed=seed,\n",
    "    save_to_dir=new_train_masks_folder,\n",
    "    batch_size=32):\n",
    "        n +=1\n",
    "        if n > 200:\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing train images and masks ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 6409/6409 [00:10<00:00, 602.18it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6409/6409 [00:03<00:00, 1874.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "train_ids_new = os.listdir('C:/newData/new_train_images/')\n",
    "\n",
    "# Get and resize train images and masks\n",
    "X_train_new = np.zeros((len(train_ids_new), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_train_new = np.zeros((len(train_ids_new), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "\n",
    "print('Getting and resizing train images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "\n",
    "for n, id_ in tqdm(enumerate(train_ids_new), total=len(train_ids_new)):\n",
    "\n",
    "    fn_ = ''.join(['C:/newData/new_train_images/',id_])\n",
    "\n",
    "    img = imread(fn_)[:,:,:IMG_CHANNELS]\n",
    "    orig_file_height, orig_file_width = img.shape[0:2]\n",
    "\n",
    "\n",
    "    X_train_new[n] = img\n",
    "    \n",
    "#Get masks\n",
    "for z, id_ in tqdm(enumerate(train_ids_new), total=len(train_ids_new)):\n",
    "    mask_ = ''.join(['C:/newData/new_train_masks/',id_])\n",
    "    #mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "    mask = imread(mask_)\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    \n",
    "    Y_train_new[z] = mask    \n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-766f42153e02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#save the pickle files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_new\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_train_pickle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train_new\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_masks_pickle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Pickle files generated.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_new' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "#output pickle locations for X_train and Y_train\n",
    "output_train_pickle = 'C:/CompetitionData/X_train.p'\n",
    "output_masks_pickle = 'C:/CompetitionData/Y_train.p'\n",
    "\n",
    "#save the pickle files\n",
    "pickle.dump(X_train_new, open(output_train_pickle, \"wb\"))\n",
    "pickle.dump(Y_train_new, open(output_masks_pickle, \"wb\"))\n",
    "print(\"Pickle files generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
